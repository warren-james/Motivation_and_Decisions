B <- (1 - mu) * phi
p <- unlist(map2(A, B, dbeta, x = x_vals))
hpdi_dist <- data.frame(lower = numeric(),
upper = numeric())
for(ii in 1:3){
temp <- as.numeric(HDInterval::hdi(rbeta(1000, A[ii], B[ii])))
hpdi_dist <- rbind(hpdi_dist, data.frame(lower = temp[1],
upper = temp[2]))
}
result <- list("p" = p, "hpdi_dist" = hpdi_dist)
return(result)
}
# plt posterior_beta
plt_post_beta <- function(model_df, values, model, m_matrix){
plt_posterior <- tibble(
group = rep(unique(model_df$group), each = length(values)),
x = rep(values, 3),
p = post_preds_beta(model, values, m_matrix)$p) %>%
ggplot(aes(x, p, colour = group, fill = group)) +
geom_area(position = "dodge", alpha = 0.3) +
theme_minimal() +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
theme(legend.position = "bottom")
plt_posterior$labels$x <- "Posterior Distribution"
plt_posterior$labels$y <- "density"
return(plt_posterior)
}
# plotting mean effect
plt_mu_beta <- function(samples, m_matrix){
# get mu estimates
mu <- array(0, dim = c(nrow(samples$beta), nrow(m_matrix)))
for (ii in 1:nrow(samples$beta)) {
mu[ii, ] <- plogis(m_matrix %*% samples$beta[ii, ])
}
# make data frame of this
mu_df <- as.tibble(mu) %>%
`colnames<-`(c("control", "motivated", "optimal")) %>%
gather(key = "group",
value = "p_mu")
# get hdpi
hpdi_mu <- as.tibble(t(purrr::map_df(as.tibble(mu), hdi))) %>%
cbind(tibble(group = c("control", "motivated", "optimal"))) %>%
`colnames<-`(c("lower", "upper", "group")) %>%
select(group, lower, upper)
hpdi_mu
# make plt
plt_mu <- mu_df %>%
ggplot(aes(p_mu, colour = group, fill = group)) +
geom_density(alpha= 0.3) +
theme_minimal() +
theme(legend.position = "bottom") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol()
plt_mu$labels$colour <- "Group"
plt_mu$labels$fill <- "Group"
plt_mu$labels$x <- "Predicted Mean Accuracy"
plt_mu
my_list <- list(mu, mu_df, hpdi_mu, plt_mu)
return(my_list)
}
# plt shaded_mu
plt_shaded_mu_beta <- function(data_mu, data_hpdi, data_posterior){
# get mu line
mu_line <- data.frame(group = character(),
x = numeric(),
y = numeric())
# get density profile
for(ii in unique(data_mu$group)){
temp <- filter(data_mu[data_mu$group == ii,])
x <- density(temp$p_mu)$x
y <- density(temp$p_mu)$y
mu_line <- rbind(mu_line, data.frame(group = ii,
x = x,
y = y))
}
# now make plot
plt_shaded_mu <- merge(mu_line, data_hpdi) %>%
mutate(variable = ifelse(x > lower & x < upper, 1, 0))
plt_shaded_mu <- ggplot(data_posterior,
aes(colour = group,
fill = group)) +
geom_line(aes(x, p)) +
geom_area(data = filter(plt_shaded_mu, variable == 1),
position = "dodge",
aes(x = x,
y = y),
alpha = 0.3) +
theme_minimal() +
theme(legend.position = "bottom") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
scale_x_continuous(limits = c(0.5, 0.9))
plt_shaded_mu$labels$colour <- "Group"
plt_shaded_mu$labels$fill <- "Group"
plt_shaded_mu$labels$x <- "Predicted Accuracy"
plt_shaded_mu$labels$y <- "Density"
plt_shaded_mu
return(plt_shaded_mu)
}
# plt difference for means
plt_diff_beta <- function(mu){
plt_diff <- tibble(control = mu[,1],
motivated = mu[,2],
optimal = mu[,3]) %>%
mutate("Motivated - Control" = motivated - control,
"Optimal - Control" = optimal - control,
"Optimal - Motivated" = optimal - motivated) %>%
select(-control,
-motivated,
-optimal) %>%
gather(key = "Comparison",
value = "Difference") %>%
ggplot(aes(Difference,
colour = Comparison,
fill = Comparison)) +
geom_density(alpha = 0.3) +
geom_vline(xintercept = 0,
linetype = "dashed") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
theme_minimal() +
theme(legend.position = "bottom")
# return plt
return(plt_diff)
}
# post for berno
post_berno <- function(model, x_vals, m_matrix){
post <- rstan::extract(model)
beta <- colMeans(post$beta)
mu <- m_matrix %*% beta
p <- logistic(mu)
return(p)
}
#### PLOTTING MODELS ####
#### BETA ####
# setup effects
X <- tibble(intercept = c(1,1,1),
motivated = c(0,1,0),
optimal = c(0,0,1))
X <- as.matrix(X)
# sequence to estimate likelihood
x_vals <- seq(0,1-0.001,0.001)
#### m1: acc ~ group ####
load("modelling/model_data/beta_1")
load("modelling/model_outputs/m_stan_group_beta_1")
samples <- rstan::extract(m_stan_group)
plt_posterior <- plt_post_beta(model_data, x_vals, m_stan_group, X)
plt_posterior <- plt_posterior +
scale_x_continuous(limits = c(0.5, 0.9)) +
scale_y_continuous(breaks = seq(0,15,5))
plt_posterior
ggsave("../Figures/Model_stan_rawacc.png",
height = 5,
width = 8)
mu_list <- plt_mu_beta(samples, X)
mu <- mu_list[[1]]
mu_df <- mu_list[[2]]
hpdi_mu <- mu_list[[3]]
plt_mu <- mu_list[[4]]
plt_mu
plt_shaded_mu <- plt_shaded_mu_beta(plt_mu[["data"]], hpdi_mu, plt_posterior[["data"]])
plt_shaded_mu
plt_diff <- plt_diff_beta(mu)
plt_diff
plt_save <- gridExtra::grid.arrange(plt_posterior, plt_diff, ncol = 2)
ggsave(plt_save, file = "../Figures/Model_stan_rawacc_compare.png",
height = 5,
width = 13)
load("modelling/model_data/beta_2")
load("modelling/model_outputs/m_stan_group_beta_2")
samples <- rstan::extract(m_stan_group_exp)
plt_posterior <- plt_post_beta(model_data, x_vals, m_stan_group_exp, X)
plt_posterior <- plt_posterior +
scale_x_continuous(limits = c(0.5, 0.9)) +
scale_y_continuous(breaks = seq(0,15,5))
plt_posterior
ggsave("../Figures/Model_stan_expacc.png",
height = 5,
width = 8)
mu_list <- plt_mu_beta(samples, X)
mu <- mu_list[[1]]
mu_df <- mu_list[[2]]
hpdi_mu <- mu_list[[3]]
plt_mu <- mu_list[[4]]
plt_mu
View(m_stan_group)
plt_shaded_mu <- plt_shaded_mu_beta(plt_mu[["data"]], hpdi_mu, plt_posterior[["data"]])
plt_shaded_mu
plt_diff <- plt_diff_beta(mu)
plt_diff
plt_save <- gridExtra::grid.arrange(plt_posterior, plt_diff, ncol = 2)
ggsave(plt_save, file = "../Figures/Model_stan_expacc_compare.png",
height = 5,
width = 13)
rm(list = ls())
setwd("F:/Uni/Github/Motivation_and_Decisions/Analysis")
#### modelling penguin ####
# This script is to work on modelling the data
# from the penguin version of the task with other
# control versions (using instructed and practice from
# the transfer paper)
#### Library ####
library(brms)
library(rethinking)
library(rstan)
library(tidybayes)
library(tidyverse)
#### constants ####
Screen_dist <- 60
x_res <- 1920
x_width <- 54
ppcm <- x_res/x_width
# NB: setting seed to make results reproducible
set.seed(12345)
#### Functions ####
# get visual degrees
get_VisDegs <- function(size,distance){
((2*atan2(size,(2*distance)))*180)/pi
}
#### load in data ####
load("scratch/all_data")
df_all <- df
#tidy
rm(df)
# work out expected accuracy?
# motivated
load("scratch/acc_sep_peng")
acc_sep_peng <- acc_sep %>%
mutate(participant = paste(participant,
"motivated",
sep = "_"))
# control + optimal
load("scratch/acc_sep_contopt")
load("scratch/df_groupID")
acc_sep <- merge(acc_sep, df_groupID) %>%
mutate(participant = paste(participant, group, sep = "_")) %>%
select(-group) %>%
rbind(acc_sep_peng)
# tidy
rm(acc_sep_peng)
# bind this to df
acc_sep_1 <- acc_sep %>%
mutate(separation_1 = separation,
accuracy_1 = accuracy) %>%
select(-separation, -accuracy)
acc_sep_2 <- acc_sep %>%
mutate(separation_2 = separation,
accuracy_2 = accuracy) %>%
select(-separation, -accuracy)
df_all <- df_all %>%
mutate(separation_1 = separation*centre,
separation_2 = (separation*2)-separation_1)
# merge this
df_all<- merge(df_all, acc_sep_1)
df_all<- merge(df_all, acc_sep_2) %>%
mutate(accuracy = (accuracy_1 + accuracy_2)/2) %>%
select(-separation_1, -separation_2,
-accuracy_1, -accuracy_2)
# tidy
rm(acc_sep_1, acc_sep_2)
#### remove participant that didn't complete 4 blocks ####
df_all <- df_all %>%
group_by(participant) %>%
filter(max(block) == 4)
# plot something to check
df_all%>%
group_by(participant, group) %>%
summarise(predicted = mean(accuracy),
actual = mean(correct)) %>%
gather(predicted:actual,
key = "type",
value = "accuracy") %>%
ggplot(aes(accuracy, colour = group, fill = group)) +
geom_density(alpha = 0.3) +
theme_minimal() +
facet_wrap(~type)
# save this
save(df_all, file = "scratch/df_all")
model_data <- df_all %>%
select(participant, group, correct)
m_matrix <- model.matrix(correct ~ group, data = model_data)
stan_df <- list(
N = nrow(model_data),
K = ncol(m_matrix),
y = model_data$correct,
X = m_matrix
)
# WIP, takes far too long, not sure why
m_stan_berno <- stan(
file = "modelling/models/stan_berno.stan",
data = stan_df,
chains = 1,
warmup = 1000,
iter = 2000,
refresh = 100
)
launch_shinystan(m_stan_berno)
m_stan_berno <- stan(
file = "modelling/models/stan_berno.stan",
data = stan_df,
chains = 1,
warmup = 1000,
iter = 2000,
refresh = 100
)
m_stan_berno <- stan(
file = "modelling/models/stan_berno.stan",
data = stan_df,
chains = 1,
warmup = 1000,
iter = 2000,
refresh = 100
)
post_berno <- function(model, x_vals, m_matrix){
post <- rstan::extract(model)
beta <- colMeans(post$beta)
# mu <- m_matrix %*% beta
p <- logistic(m_matrix %*% beta)
return(p)
}
X <- tibble(intercept = c(1,1,1),
motivated = c(0,1,0),
optimal = c(0,0,1))
X <- as.matrix(X)
# sequence to estimate likelihood
x_vals <- seq(0,1-0.001,0.001)
post_berno(m_stan_berno, x_vals, X)
samples <- rstan::extract(m_stan_berno)
summary(m_stan_berno)
save(model_data, file = "modelling/model_data/berno_1")
save(m_stan_berno, file = "modelling/model_outputs/m_stan_berno_1")
rm(list = ls())
setwd("F:/Uni/Github/Motivation_and_Decisions/Analysis")
# setup effects
X <- tibble(intercept = c(1,1,1),
motivated = c(0,1,0),
optimal = c(0,0,1))
X <- as.matrix(X)
# sequence to estimate likelihood
x_vals <- seq(0,1-0.001,0.001)
#### For plotting model outputs ####
#### Library ####
library(brms)
library(rethinking)
library(rstan)
library(tidybayes)
library(tidyverse)
#### constants ####
Screen_dist <- 60
x_res <- 1920
x_width <- 54
ppcm <- x_res/x_width
# NB: setting seed to make results reproducible
set.seed(12345)
#### Functions ####
# get visual degrees
get_VisDegs <- function(size,distance){
((2*atan2(size,(2*distance)))*180)/pi
}
# get posterior preds for beta dist
post_preds_beta <- function(model, x_vals, m_matrix){
post <- rstan::extract(model)
beta <- colMeans(post$beta)
gamma <- colMeans(post$gamma)
mu  <- plogis(m_matrix %*% beta)
phi <- exp(m_matrix %*% gamma)
A <- mu * phi
B <- (1 - mu) * phi
p <- unlist(map2(A, B, dbeta, x = x_vals))
hpdi_dist <- data.frame(lower = numeric(),
upper = numeric())
for(ii in 1:3){
temp <- as.numeric(HDInterval::hdi(rbeta(1000, A[ii], B[ii])))
hpdi_dist <- rbind(hpdi_dist, data.frame(lower = temp[1],
upper = temp[2]))
}
result <- list("p" = p, "hpdi_dist" = hpdi_dist)
return(result)
}
# plt posterior_beta
plt_post_beta <- function(model_df, values, model, m_matrix){
plt_posterior <- tibble(
group = rep(unique(model_df$group), each = length(values)),
x = rep(values, 3),
p = post_preds_beta(model, values, m_matrix)$p) %>%
ggplot(aes(x, p, colour = group, fill = group)) +
geom_area(position = "dodge", alpha = 0.3) +
theme_minimal() +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
theme(legend.position = "bottom")
plt_posterior$labels$x <- "Posterior Distribution"
plt_posterior$labels$y <- "density"
return(plt_posterior)
}
# plotting mean effect
plt_mu_beta <- function(samples, m_matrix){
# get mu estimates
mu <- array(0, dim = c(nrow(samples$beta), nrow(m_matrix)))
for (ii in 1:nrow(samples$beta)) {
mu[ii, ] <- plogis(m_matrix %*% samples$beta[ii, ])
}
# make data frame of this
mu_df <- as.tibble(mu) %>%
`colnames<-`(c("control", "motivated", "optimal")) %>%
gather(key = "group",
value = "p_mu")
# get hdpi
hpdi_mu <- as.tibble(t(purrr::map_df(as.tibble(mu), hdi))) %>%
cbind(tibble(group = c("control", "motivated", "optimal"))) %>%
`colnames<-`(c("lower", "upper", "group")) %>%
select(group, lower, upper)
hpdi_mu
# make plt
plt_mu <- mu_df %>%
ggplot(aes(p_mu, colour = group, fill = group)) +
geom_density(alpha= 0.3) +
theme_minimal() +
theme(legend.position = "bottom") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol()
plt_mu$labels$colour <- "Group"
plt_mu$labels$fill <- "Group"
plt_mu$labels$x <- "Predicted Mean Accuracy"
plt_mu
my_list <- list(mu, mu_df, hpdi_mu, plt_mu)
return(my_list)
}
# plt shaded_mu
plt_shaded_mu_beta <- function(data_mu, data_hpdi, data_posterior){
# get mu line
mu_line <- data.frame(group = character(),
x = numeric(),
y = numeric())
# get density profile
for(ii in unique(data_mu$group)){
temp <- filter(data_mu[data_mu$group == ii,])
x <- density(temp$p_mu)$x
y <- density(temp$p_mu)$y
mu_line <- rbind(mu_line, data.frame(group = ii,
x = x,
y = y))
}
# now make plot
plt_shaded_mu <- merge(mu_line, data_hpdi) %>%
mutate(variable = ifelse(x > lower & x < upper, 1, 0))
plt_shaded_mu <- ggplot(data_posterior,
aes(colour = group,
fill = group)) +
geom_line(aes(x, p)) +
geom_area(data = filter(plt_shaded_mu, variable == 1),
position = "dodge",
aes(x = x,
y = y),
alpha = 0.3) +
theme_minimal() +
theme(legend.position = "bottom") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
scale_x_continuous(limits = c(0.5, 0.9))
plt_shaded_mu$labels$colour <- "Group"
plt_shaded_mu$labels$fill <- "Group"
plt_shaded_mu$labels$x <- "Predicted Accuracy"
plt_shaded_mu$labels$y <- "Density"
plt_shaded_mu
return(plt_shaded_mu)
}
# plt difference for means
plt_diff_beta <- function(mu){
plt_diff <- tibble(control = mu[,1],
motivated = mu[,2],
optimal = mu[,3]) %>%
mutate("Motivated - Control" = motivated - control,
"Optimal - Control" = optimal - control,
"Optimal - Motivated" = optimal - motivated) %>%
select(-control,
-motivated,
-optimal) %>%
gather(key = "Comparison",
value = "Difference") %>%
ggplot(aes(Difference,
colour = Comparison,
fill = Comparison)) +
geom_density(alpha = 0.3) +
geom_vline(xintercept = 0,
linetype = "dashed") +
ggthemes::scale_color_ptol() +
ggthemes::scale_fill_ptol() +
theme_minimal() +
theme(legend.position = "bottom")
# return plt
return(plt_diff)
}
# post for berno
post_berno <- function(model, x_vals, m_matrix){
post <- rstan::extract(model)
beta <- colMeans(post$beta)
# mu <- m_matrix %*% beta
p <- logistic(m_matrix %*% beta)
return(p)
}
X <- tibble(intercept = c(1,1,1),
motivated = c(0,1,0),
optimal = c(0,0,1))
X <- as.matrix(X)
# sequence to estimate likelihood
x_vals <- seq(0,1-0.001,0.001)
#### m1: correct ~ group ####
load("modelling/model_data/berno_1")
load("modelling/model_outputs/m_stan_berno_1")
samples <- rstan::extract(m_stan_berno)
